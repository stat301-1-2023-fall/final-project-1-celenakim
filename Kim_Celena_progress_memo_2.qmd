---
title: "Progress Memo 2"
subtitle: |
  | Final Project 
  | Data Science 1 with R (STAT 301-1)
author: "Celena Kim"
date: today

format:
  html:
    toc: true
    embed-resources: true
    code-fold: show
    link-external-newwindow: true
    
execute:
  warning: false

from: markdown+emoji 
---


::: {.callout-tip icon="false"}
## Github Repo Link

[https://github.com/stat301-1-2023-fall/final-project-1-celenakim](https://github.com/stat301-1-2023-fall/final-project-1-celenakim)
:::

## Packages & Datasets
The data used in this project is called [Hollywood Hits and Flops (2007 - 2023)](https://www.kaggle.com/datasets/sujaykapadnis/hollywood-hits-and-flops-2007-2023/) found on [Kaggle](https://www.kaggle.com). 

```{r}
#| label: load-pkgs-data
#| echo: false

library(tidyverse)
library(janitor)
data_2007 <- read.csv("data/The Hollywood Inider - all data - 2007.csv")
data_2008 <- read.csv("data/The Hollywood Inider - all data - 2008.csv")
data_2009 <- read.csv("data/The Hollywood Inider - all data - 2009.csv")
data_2010 <- read.csv("data/The Hollywood Inider - all data - 2010.csv")
data_2011 <- read.csv("data/The Hollywood Inider - all data - 2011.csv")
data_2012 <- read.csv("data/The Hollywood Inider - all data - 2012.csv")
data_2013 <- read.csv("data/The Hollywood Inider - all data - 2013.csv")
data_2014 <- read.csv("data/The Hollywood Inider - all data - 2014.csv")
data_2015 <- read.csv("data/The Hollywood Inider - all data - 2015.csv")
data_2016 <- read.csv("data/The Hollywood Inider - all data - 2016.csv")
data_2017 <- read.csv("data/The Hollywood Inider - all data - 2017.csv")
data_2018 <- read.csv("data/The Hollywood Inider - all data - 2018.csv")
data_2019 <- read.csv("data/The Hollywood Inider - all data - 2019.csv")
data_2020 <- read.csv("data/The Hollywood Inider - all data - 2020.csv")
data_2021 <- read.csv("data/The Hollywood Inider - all data - 2021.csv")
data_2022 <- read.csv("data/The Hollywood Inider - all data - 2022.csv")
```


## Joining Datasets
```{r}
#| echo: false
data_2011 <- data_2011[, -ncol(data_2011)]

data_2012 <- data_2012[, -ncol(data_2012)]

data_2013 <- data_2013[, -ncol(data_2013)]

data_2014 <- data_2014[, -ncol(data_2014)]

data_2015 <- data_2015[, -ncol(data_2015)]

data_2016 <- data_2016[, -ncol(data_2016)]

data_2017 <- data_2017[, -ncol(data_2017)]

data_2018 <- data_2018[, -ncol(data_2018)]

data_2019 <- data_2019 |> 
  rename(Genre = Genres, Opening.Weekend = Opening.Weekend...., 
         of.Gross.earned.abroad = X..of.Gross.earned.abroad)
data_2019 <- data_2019[, -c((ncol(data_2019) - 1):ncol(data_2019))]

data_2020 <- data_2020 |> 
  rename(Genre = Genres, Opening.Weekend = Opening.Weekend...., 
         of.Gross.earned.abroad = X..of.Gross.earned.abroad) 
data_2020 <- data_2020[, -c((ncol(data_2020) - 1):ncol(data_2020))]

data_2021 <- data_2021 |> 
  rename(Genre = Genres, Opening.Weekend = Opening.Weekend...., 
         of.Gross.earned.abroad = X..of.Gross.earned.abroad) 
data_2021 <- data_2021[, -c((ncol(data_2021) - 1):ncol(data_2021))]

data_2022 <- data_2022 |> 
  rename(Genre = Genres, Opening.Weekend = Opening.Weekend...., 
         of.Gross.earned.abroad = X..of.Gross.earned.abroad) 
data_2022 <- data_2022[, -c((ncol(data_2022) - 1):ncol(data_2022))]

movie_data <- rbind(data_2007, data_2008, data_2009, 
                    data_2010, data_2011, data_2012, 
                    data_2013, data_2014, data_2015, 
                    data_2016, data_2017, data_2018, 
                    data_2019, data_2020, data_2021, 
                    data_2022)

write.csv(movie_data, "movie_data.csv", row.names = FALSE)
```
There are 16 different csv files corresponding to a year from 2007-2023, so joining data sets was necessary. However, there were some discrepancies between the data sets, so some preliminary cleaning was needed. First, the data sets had different numbers of columns with the years 2011-2022 having one or two extra variables: "film list" and "financial source". These variables were not necessary for my analysis, so I simply removed them from those data sets and ended up with 33 variables in all 16 files. Next, I noticed that there were some slight differences in column names, such as "Genres" vs. "Genres", so I skimmed through the variable names in each file and ensured that all were uniform. After these changes, all 16 files matched in column number and variable name, so I was then able to combine all of them into one data set: "movie_data".


## Data Cleaning
```{r}
#| echo: false
# Changing variable names to snake case
movie_data <- clean_names(movie_data)

# Deleting unnecessary variables
drop = c("link", "none")
movie_data = movie_data[,!(names(movie_data) %in% drop)]

# Changing character variables to integers when needed
char_vector <- c("rotten_tomatoes_critics", "metacritic_critics", 
                 "average_critics", "metacritic_audience",
                 "rotten_tomatoes_vs_metacritic_deviance", 
                 "average_audience", "audience_vs_critics_deviance", 
                 "opening_weekend", "opening_weekend_million", 
                 "domestic_gross", "domestic_gross_million", 
                 "foreign_gross_million", "foreign_gross", 
                 "worldwide_gross", "worldwide_gross_million", 
                 "budget_million")

# Convert the character vector to integer
movie_data <- movie_data %>%
  mutate_at(char_vector, ~as.integer(.))

# Replace NA values in 'genre' with values from 'primary_genre'
movie_data <- movie_data %>%
  mutate(genre = ifelse(is.na(genre) | 
                          genre == "-",
                        primary_genre, 
                        genre))

# Changing "oscar_winners" variable to boolean
movie_data <- movie_data %>%
  mutate(oscar_winners = ifelse(oscar_winners == "", 
                                FALSE, 
                                TRUE))
```
After my files were condensed into one main data set, I did a bit more data set cleaning. First, the variable names were not in snake case form, so I fixed that using the clean_names() function. Next, I noticed that there were more unnecessary variables-- "link", which provided an Amazon link to the movie, and "None", which just had NAs-- so I decided to remove them from the data set as well. Third, after glimpsing my data, I noticed that variables such as critic ratings and domestic gross earnings were character type variables rather than integers, so I converted those variables into integers using as.integer(). Next, I noticed that there were NAs for some movies' "genre" variable, even though they had a value "primary genre", so I made an ifelse statement that set a movie's NA in "genre" to its "primary genre". And finally, in order to be able to do analyses with the "oscar_winners" variable, I changed it's type to be a boolean using an ifelse statement.


## Exploration 1: What is the most popular/successful genre?
- opening weekend success
- oscar winner success
```{r}
#| echo: false
unique_genres <- unique(movie_data$genre)

genre_opening_success <- movie_data |> 
  group_by(genre) |> 
  summarize(mean_opening_success = mean(opening_weekend)) |> 
  arrange(desc(mean_opening_success)) |> 
  slice_head(n = 3) |> 
  DT::datatable()
genre_opening_success

genre_oscar_counts <- movie_data |> 
  group_by(genre) |> 
  summarize(oscar_count = sum(oscar_winners)) |> 
  arrange(desc(oscar_count)) |> 
  slice_head(n = 3)|> 
  DT::datatable()
genre_oscar_counts
```
In terms of mean opening weekend earnings success, the "sci-fi & fantasy" genre was the most successful as this genre combination had the highest earnings. In terms of Oscar win success, the "biography & history" genre was the most successful as this genre combination earned the most amount of Oscars.


## Exploration 2: What is the most popular/successful script type?

```{r}
#| echo: false
scripttype_opening_success <- movie_data |> 
  group_by(script_type) |> 
  summarize(mean_opening_success = round(mean(opening_weekend))) |> 
  arrange(desc(mean_opening_success)) |> 
  slice_head(n = 3) |> 
  DT::datatable()
scripttype_opening_success

scripttype_oscar_counts <- movie_data |> 
  group_by(script_type) |> 
  summarize(oscar_count = sum(oscar_winners)) |> 
  arrange(desc(oscar_count)) |> 
  slice_head(n = 3)|> 
  DT::datatable()
scripttype_oscar_counts
```
The script type combination that is the most successful during opening weekend is "sequel & adaptation". The script type that earned the most Oscars is "original screenplay".

## Exploration 3: What changes over the years from 2007-2022?
```{r}
#| echo: false
year_opening_success <- movie_data |> 
  group_by(year) |> 
  summarize(mean_opening_success = round(mean(opening_weekend_million, na.rm = TRUE)))  |> 
  arrange(desc(mean_opening_success)) 

year_opening_success |> 
  DT::datatable()

ggplot(year_opening_success, aes(x = year, y = mean_opening_success)) +
  geom_line() +
  geom_point() +
  labs(x = "Year", y = "Mean Opening Weekend Earnings (in millions)", title = "Average Opening Weekend Earnings for Hollywood Movies from 2007-2022") +
  ylim(0, 28)
```
These visualizations represent the change in the mean opening weekend earnings (in millions) for Hollywood movies from 2007-2008. As can be seen by the graph, the years with the most successful opening weekends in terms of mean earnings are the years 2012 and 2014, closely tied with an average earning of 27 million dollars. The lowest point on the graph corresponds to 2020, with that year earning the least during opening weekend: 8 million dollars. This data definitely reflects the times/economy of the country during this year, as 2020 was the year that America was under quarantine and movie theaters were shut down.


## Exploration 4: What affects likelihood of getting Oscar?



## Exploration 5: Comparing domestic vs foreign vs worldwide gross?


## Exploration 6: Opening weekend success vs. budget recovered?


